{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducción\n",
    "Aprendizaje supervisado: cada observación tiene una respuesta asociada que guía el aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "df  = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entendimiento del problema\n",
    "Entender el problema en Machine Learning es el primer paso a resolver de todo científico de datos, requiere de habilidades de escucha, comunicación, comprensión y pensamiento crítico. La meta es identificar y expresar con claridad el problema que se no asignó y la solución pedida, para ello necesitamos realizar las preguntas correctas y comunicar de forma clara nuestras deducciones. Este proyecto funciona como un ejemplo básico y didáctico sobre un conjunto de datos cuyo propósito es caracterizar mediante variables cualitativas(nominales y ordinales) y variables cuantitativas(discretas y continuas) a los pasajeros que estuvieron en la tragedia de Titanic, de esta forma es entendible que el objetivo es analizar y describir que ha sucedido para luego averiguar el síntoma de las variables descriptivas sobre las variables clasificadoras que indican la supervivencia de cada pasajero, como análisis final se busca generar un modelo que asocie un resultado a una clasificación en base a la información disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputación de datos faltantes mediante medias y modas\n",
    "\n",
    "df.fillna({\"Age\":df[\"Age\"].mean()},inplace=True)\n",
    "\n",
    "mode = df[\"Embarked\"].mode()\n",
    "df.fillna({\"Embarked\":mode[0]},inplace=True)\n",
    "\n",
    "# codificando variables categóricas nominales\n",
    "\n",
    "df[\"Sex_encoded\"] = LabelEncoder().fit_transform(df[\"Sex\"])\n",
    "\n",
    "# a su vez generamos una versión textual de la variable binaria objetivo\n",
    "\n",
    "map_survived = {\n",
    "    0:\"no\",\n",
    "    1:\"yes\"\n",
    "}\n",
    "df[\"Survived_no_encoded\"] = df[\"Survived\"].apply(lambda x : map_survived.get(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Categóricas y Datasets Desbalanceados\n",
    "La función de las variables categóricas es brindar información clasificando las observaciones, puenden demostrar una influencia en los datos permitiendonos determinar comportamientos o sacar conclusiones premeditadas si los datos influyen en estas. Los Trip_Priceos de variables categóricas que hay son nominales: aquellas que actúan como etiquetas de los objetos(dentro de estas pueden encontrarse las que se dividen en 2 clases y su codificación las convierte en binarias, es decir, valores posibles de 0 o 1) y ordinales: aquellas que representan un órden jerárquico en particular que rige en las observaciones.\n",
    "\n",
    "En algunos casos los Datasets tienden a contener más cantidades de datos categóricos que otros, esto puede llegar a traer problemas la hora de entrenar un modelo o evaluar el desempeño de este debido a que la variable minoritaria tiende a ser ignorada y genera un sesgo en cuanto a la importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_count = df[\"Survived\"].value_counts().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].bar(survived_count[\"Survived_encoded\"], survived_count[\"count\"], color=[\"b\",\"orange\"])\n",
    "ax[0].grid(\"on\")\n",
    "ax[0].set_title('Conteo de clases')\n",
    "ax[1].pie(survived_count[\"count\"], labels=survived_count[\"Survived_encoded\"], autopct='%1.1f%%')\n",
    "ax[1].set_title('Porciones de clase')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CART(classification and regression trees)\n",
    "Algoritmos basados en calcular umbrales que determinen el resultado de una variable, de manera iterativa se generan particiones sobre la región de información hasta llegar a una formación de grupo lo más homogénea posible. Haciendo analogía a la estructura de un árbol, a partir de la raíz principal se extienden nodos adicionales que representan una condición y hojas que indican la pureza en su región de clases, de esta manera su trayectoria consiste en integorrantes de si o no junto con respuestas asociadas y la fiabilidad de estas. El modelado a partir de esta técnica de aprendizaje requiere controlar la complejidad del árbol de decisión, siendo la pre-poda la acción de limitar el crecimiento durante el proceso de entrenamiento y la post-poda lo mismo luego de este último, esto se realiza mediante la programación de valores númericos definidos y asignados por el usuario, es decir, un ajuste de hiperparámetros y aglunos ejemplos son definir la profundidad máxima o el mínimo número de muestras requeridas para cada partición o hoja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seccionamos los datos en grupos de entrenamiento y prueba\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                   df[[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"]],\n",
    "                                                   df[\"Survived\"],\n",
    "                                                   test_size=0.12)\n",
    "\n",
    "# declaración del algoritmo\n",
    "\n",
    "tree_decision_clf = tree.DecisionTreeClassifier(criterion=\"entropy\", # medida de aleatoriedad, determinará los nodos del modelo en base a la probabilidad de clasificar erroneamente una variable, pero sin darle mayor importancias a ciertas características\n",
    "                                           max_depth=6, # distancia entre el nodo(condición) principal y la última hoja(respuesta asociada), valores recomendados: 3-10\n",
    "                                           min_samples_split=6, # mínimo número de muestras requeridas para dividir un nodo, valores recomendados: 2-10\n",
    "                                           min_samples_leaf=5, #  mínimo número de muestras requeridas en cada hoja, valores recomendados: 1-10\n",
    "                                           ccp_alpha=0.003) # valor de post-poda(luego de que el modelo se ajute) que evita el sobreajuste \n",
    "\n",
    "model = tree_decision_clf.fit(x_train, y_train)\n",
    "\n",
    "# predicción de los datos de prueba\n",
    "\n",
    "class_predicts = model.predict(x_test)\n",
    "\n",
    "class_real = y_test.values\n",
    "\n",
    "# Matriz de confusión: recolecta los aciertos y desaciertos tanto de la clase postiva como negativa del modelo\n",
    "\n",
    "matrix_confusion = confusion_matrix(class_real,class_predicts)\n",
    "TP = matrix_confusion[0,0]\n",
    "FP = matrix_confusion[0,1]\n",
    "FN = matrix_confusion[1,0]\n",
    "TN = matrix_confusion[1,1]\n",
    "\n",
    "# Accuracy: indica la acertividad general de nuestro modelo con respecto a las nuevas observaciones\n",
    "\n",
    "accuracy = accuracy_score(class_real, class_predicts)\n",
    "color_accuracy = \"green\"\n",
    "if accuracy < 0.6:\n",
    "    color_accuracy = \"red\"\n",
    "accuracy_str = str(accuracy)\n",
    "\n",
    "# Recall: es utilizada para poder saber la efectividad de nuestro modelo a la hora de predecir valores de la clase positiva\n",
    "\n",
    "recall = recall_score(class_real, class_predicts)\n",
    "color_recall = \"green\"\n",
    "if recall < 0.6:\n",
    "    color_recall = \"red\"\n",
    "recall_str = str(recall)\n",
    "\n",
    "# Precision: es utilizada para poder saber que porcentage de valores que fueron clasificados como positivos son realmente positivos\n",
    "\n",
    "precision = precision_score(class_real, class_predicts)\n",
    "color_precision = \"green\"\n",
    "if precision < 0.6:\n",
    "    color_precision = \"red\"\n",
    "precision_str = str(precision)\n",
    "\n",
    "# F1 Score: es utilizada como un resumen de las dos últimas metricas\n",
    "\n",
    "F1_score = f1_score(class_real, class_predicts)\n",
    "color_f1 = \"green\"\n",
    "if F1_score < 0.6:\n",
    "    color_f1 = \"red\"\n",
    "F1_score_str = str(F1_score)\n",
    "\n",
    "print(tree.export_text(model, feature_names=[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"]))\n",
    "\n",
    "plt.figure(figsize=(35,22))\n",
    "tree.plot_tree(model, feature_names=[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashboard que muestra las probabilidades de sobrevivir según las variables y el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2bdf53bf920>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creación de dashboard basado en la estructura HTML/CSS\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(id=\"body\",className=\"e1_body\",children=[\n",
    "html.H1(\"Titanic\",id=\"title\",className=\"e1_title\"),\n",
    "html.Div(className=\"e1_dashboards\",children=[\n",
    "    html.Div(id=\"graph_div_1\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_1\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_1\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Sexo\",\"value\":\"Sex\"},\n",
    "                            {\"label\":\"Clase social\",\"value\":\"Pclass\"},\n",
    "                            {\"label\":\"Embarcadero\",\"value\":\"Embarked\"},\n",
    "                            {\"label\":\"Padres e hijos/as\",\"value\":\"Parch\"},\n",
    "                            {\"label\":\"Hermanas/os y esposas/os\",\"value\":\"SibSp\"},\n",
    "                        ],\n",
    "                        value=\"Sex\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"piechart\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "    html.Div(id=\"graph_div_2\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_2\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_2\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Edad\",\"value\":\"Age\"},\n",
    "                            {\"label\":\"Boleto\",\"value\":\"Fare\"},\n",
    "                        ],\n",
    "                        value=\"Age\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"bar\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "]),\n",
    "    \n",
    "    html.Div(className=\"e1_div\", children=[\n",
    "        html.Div(id=\"performance\", className=\"e1_performance\",children=[\n",
    "            html.P([html.B(\"Clases reales\", style={\"color\":\"blue\"}),\"   |   \",html.B(\"Predicciones\",style={\"color\":\"red\"})], style={\"text-align\":\"center\",\"font-family\":\"sans-serif\"}),\n",
    "            html.P(\"--------------------------------------------------------------------------------------------------------------------------------------\",style={\"margin\":\"0\"}),\n",
    "            html.P(f\"{class_real}\", className=\"e1_real_class\"),\n",
    "            html.P(f\"{class_predicts}\", className=\"e1_predicts\")\n",
    "        ]),\n",
    "        html.Div(id=\"metrics\", className=\"e1_metrics\", children=[\n",
    "                html.P(\"Matriz de confusión\", style={\"font-size\":\"0.9em\",\"text-align\":\"center\",\"font-family\":\"sans-serif\",\"font-weigth\":\"bold\"}),\n",
    "                html.Div(id=\"matrix\", className=\"e1_matrix\", children=[\n",
    "                html.Div([html.B(TP,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TP\",className=\"e1_successes\"), \n",
    "                html.Div([html.B(FP,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FP\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(FN,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FN\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(TN,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TN\",className=\"e1_successes\")\n",
    "                ]),\n",
    "                html.Div(id=\"scores\",children=[\n",
    "                html.Ul(id=\"list\",children=[\n",
    "                html.Li([f\"Accuracy: \",html.B(accuracy_str[:4],style={\"color\":f\"{color_accuracy}\"})],id=\"accuracy\",className=\"e1_score\"),\n",
    "                html.Li([f\"Recall: \",html.B(recall_str[:4],style={\"color\":f\"{color_recall}\"})],id=\"recall\",className=\"e1_score\"),\n",
    "                html.Li([f\"Precision: \",html.B(precision_str[:4],style={\"color\":f\"{color_precision}\"})],id=\"precision\",className=\"e1_score\"),\n",
    "                html.Li([f\"F1 Score: \",html.B(F1_score_str[:4],style={\"color\":f\"{color_f1}\"})],id=\"f1_score\",className=\"e1_score\")\n",
    "                ])\n",
    "                \n",
    "            ])\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "# generan interacción entre los datos de entrada y los elementos que serán modificados \n",
    "\n",
    "@app.callback(\n",
    "    [Output(component_id=\"piechart\",component_property=\"figure\"),\n",
    "    Output(component_id=\"bar\",component_property=\"figure\")],\n",
    "    [Input(component_id=\"dropdown_1\",component_property=\"value\"),\n",
    "    Input(component_id=\"dropdown_2\",component_property=\"value\")]\n",
    ")\n",
    "\n",
    "# función que se ejecuta cada vez que se interactúa con los elementos \n",
    "\n",
    "def update_graph(slct_var_cat,slct_var_num):\n",
    "    \n",
    "    df_percentage = df.groupby(slct_var_cat)[\"Survived\"].mean().reset_index()\n",
    "    df_percentage[\"Survived\"] = round(df_percentage[\"Survived\"] * 100)\n",
    "    df_percentage[\"Survived\"] = df_percentage[\"Survived\"].astype(str)\n",
    "    df_percentage[\"var_percentage\"] = df_percentage[slct_var_cat].astype(str)+\"(\"+df_percentage[\"Survived\"]+\"%)\"\n",
    "    \n",
    "    piechart = px.pie(df_percentage, values=\"Survived\", names=\"var_percentage\", title=\"Probabilidad de supervivencia\")\n",
    "    \n",
    "    df_mean = df.groupby(\"Survived_no_encoded\")[slct_var_num].mean().reset_index()\n",
    "    \n",
    "    barplot = px.bar(df_mean, x=\"Survived_no_encoded\", y=slct_var_num, title=\"Medias de Edad y Boleto\",labels={\"x\":\"sobrevivientes\",\"y\":slct_var_num})\n",
    "    barplot.update_layout(xaxis_title=\"Sobrevivientes\")\n",
    "    \n",
    "    return piechart,barplot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error de varianza\n",
    "\n",
    "Es la variabilidad que existe en la función objetivo con respecto a los diferentes datos de entrenamiento que se utilicen para la creación del modelo, sucede principalmente en algoritmos que se ajustan fácilmente a los datos y requieren menos suposiciones a diferencia de los algoritmos con alto bías, algunos ejemplos de algoritmos con alta variranza son: KNN, CART o SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "bucle = list(range(14))\n",
    "\n",
    "for i in bucle:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                   df[[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"]],\n",
    "                                                   df[\"Survived\"],\n",
    "                                                   test_size=0.25)\n",
    "    class_real = y_test.values\n",
    "    class_predicts = model.predict(x_test)\n",
    "    accuracy = accuracy_score(class_real, class_predicts)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(bucle, accuracies, marker=\"*\", c=\"r\")\n",
    "plt.grid(\"on\")\n",
    "plt.title(\"Error de Varianza\")\n",
    "plt.ylabel(\"Acuracies\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
