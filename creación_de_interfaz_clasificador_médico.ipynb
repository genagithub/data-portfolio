{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Output, Input, State\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "df_original = pd.read_csv(\"data/diabetes.csv\")\n",
    "\n",
    "df = df_original.copy()\n",
    "df.rename(columns={\"DiabetesPedigreeFunction\":\"PedigreeFunc.\"},inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(14,12))\n",
    "\n",
    "sns.boxplot(df,y=\"Glucose\",hue=\"Outcome\",ax=ax[0,0])\n",
    "ax[0,0].set_title(\"Distribución de 'Glucose' en 'Outcome'\")\n",
    "ax[0,0].grid(\"on\")\n",
    "\n",
    "sns.barplot(df,x=\"Outcome\",y=\"Glucose\",ax=ax[0,1])\n",
    "ax[0,1].set_title(\"Media de 'Glucose' en 'Outcome'\")\n",
    "\n",
    "sns.heatmap(df.corr(),annot=True,ax=ax[1,0])\n",
    "ax[1,0].set_title(\"Mapa de calor para cada correlación pearson\")\n",
    "\n",
    "sns.scatterplot(df,x=\"Glucose\",y=\"Insulin\",hue=\"Outcome\",ax=ax[1,1])\n",
    "ax[1,1].set_title(\"Correlación entre 'Glucose' y 'Insulin'\")\n",
    "ax[1,1].grid(\"on\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engireering\n",
    "Es el proceso de seleccionar las variables indicadas, eliminar las que no sirven y transformar las que requieren un preprocesamiento para potenciar la eficazia de un modelo. Una técnica implementada es el Análisis de Componentes Principales(PCA), cuyo fundamento se basa en conceptos de álgebra lineal y su objetivo en la reducción de la dimensionalidad pero conservando a su vez la mayor cantidad de información, proyectando una especie de sombra en los datos. Se implementa a la hora de combatir la maldición de la dimensionalidad, permitir crear gráficos cartesianos y facilitar el trabajo a algoritmos que no sean robustos, como en este ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionando las variables más explicativas\n",
    "df = df.loc[:,[\"Glucose\",\"Insulin\",\"BMI\",\"SkinThickness\",\"Outcome\"]]\n",
    "\n",
    "pca_model = PCA(n_components=2) \n",
    "\n",
    "pca = pca_model.fit_transform(df[df.columns[:-1]])\n",
    "\n",
    "# reduciendo esas variables a una dimensión de 2 componentes\n",
    "df[\"PCA_1\"] = pca.T[0]\n",
    "df[\"PCA_2\"] = pca.T[1]\n",
    "\n",
    "df = df.loc[(df[\"PCA_1\"] < 550) & (df[\"PCA_2\"] < 100),:]\n",
    "\n",
    "# Crear un gráfico de dispersión PCA \n",
    "plt.figure(figsize=(11,4))\n",
    "plt.scatter(df.loc[df[\"Outcome\"] == 0, \"PCA_1\"], df.loc[df[\"Outcome\"] == 0, \"PCA_2\"], label=\"Clase 0\")\n",
    "plt.scatter(df.loc[df['Outcome'] == 1, 'PCA_1'], df.loc[df['Outcome'] == 1, \"PCA_2\"], label=\"Clase 1\")\n",
    "plt.grid(\"on\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Figura PCA\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobreajuste\n",
    "En la siguiente celda se extrajeron específicamente un par de variables continuas formando un subconjunto sin contexto y que no brinda ninguna información en particular, esto se hizo para explicar un concepto recurrente en el aprendizaje automático y que está fuertemente relacionado con otra definición vista en el primer proyecto(análisis y predicción de rotación de empleados), siendo esta el error de varianza. El sobreajuste consiste en un modelo que se que se adaptó de forma elevada un grupo de datos, dejándolo poco preparado para afrontar nuevas observaciones. En la anterior figura se muestran las diferentes selecciones de datos de entrenamiento y prueba de cada modelo junto con su función objetivo que varía según las muestras. En este caso, se encuentra un umbral que diferencia dos agrupaciones con el fin de ilustrar un modelo conservador a sus objetos y como el cambio de elección de datos provoca un nuevo desempeño de este.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "iris[\"species_encoded\"] = LabelEncoder().fit_transform(iris[\"species\"])\n",
    "pca_iris = pca_model.fit_transform(iris[iris.columns[:4]])\n",
    "\n",
    "iris[\"PCA_1\"] = pca_iris.T[0]\n",
    "iris[\"PCA_2\"] = pca_iris.T[1]\n",
    "\n",
    "var = iris.loc[(iris[\"species\"] == \"virginica\") | (iris[\"species\"] == \"setosa\"), [\"PCA_1\",\"PCA_2\"]]\n",
    "var[\"PCA_1\"] = round(var[\"PCA_1\"]*100).astype(int)\n",
    "var[\"PCA_2\"] = round(var[\"PCA_2\"]*100).astype(int)\n",
    "\n",
    "def add_values(length, value_min, value_max):\n",
    "    new_values = np.array([])\n",
    "    for i in range(round(length)):\n",
    "        value = random.randint(value_min, value_max)\n",
    "        new_values = np.append(new_values, value)\n",
    "    return new_values\n",
    "    \n",
    "grp1_pca_1 = add_values(len(var)/2, 100, 400)\n",
    "grp1_pca_2 = add_values(len(var)/2, -100, 100)\n",
    "grp2_pca_1 = add_values(len(var)*1.5, -400, -200)\n",
    "grp2_pca_2 = add_values(len(var)*1.5, -100, 100)\n",
    "\n",
    "new_data_1 = np.array([grp1_pca_1,grp1_pca_2]).T\n",
    "new_data_2 = np.array([grp2_pca_1,grp2_pca_2]).T\n",
    "\n",
    "df_new_data_1 = pd.DataFrame(new_data_1, columns=[\"PCA_1\",\"PCA_2\"])\n",
    "df_new_data_2 = pd.DataFrame(new_data_2, columns=[\"PCA_1\",\"PCA_2\"])\n",
    "\n",
    "var = pd.concat([var, df_new_data_1, df_new_data_2])\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(18,7))\n",
    "\n",
    "def get_function_objetive(i, data_split):\n",
    "    var[\"data_split\"] = data_split\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=150)\n",
    "    knn_regressor.fit(var.loc[var[\"data_split\"] == \"data_train\", \"PCA_2\"].values.reshape(-1,1), var.loc[var[\"data_split\"] == \"data_train\", \"PCA_1\"])\n",
    "    RMSE = root_mean_squared_error(knn_regressor.predict(var.loc[var[\"data_split\"] == \"data_test\", \"PCA_2\"].values.reshape(-1,1)), var.loc[var[\"data_split\"] == \"data_test\", \"PCA_1\"])\n",
    "    sns.scatterplot(var, x=\"PCA_2\", y=\"PCA_1\", hue=\"data_split\", ax=ax[i])\n",
    "    ax[i].grid(\"on\")\n",
    "    ax[i].set_title(f\"RMSE: {str(RMSE)[:5]}\")\n",
    "\n",
    "get_function_objetive(0, np.where(var[\"PCA_1\"] < -195, \"data_train\", \"data_test\"))\n",
    "get_function_objetive(1, np.where((var[\"PCA_1\"] <= -200) & (var[\"PCA_2\"] < 40) | (var[\"PCA_1\"] > 0) & (var[\"PCA_2\"] > 0), \"data_train\", \"data_test\"))\n",
    "get_function_objetive(2, np.where((var[\"PCA_1\"].between(-300,-200)) | (var[\"PCA_1\"].between(200,400)), \"data_train\", \"data_test\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging \n",
    "es una de las principales técnicas computacionales de estadística inferencial cuya objetivo se basa en eliminar o reducir lo máximo posible la varianza en los resultados, su método es utilizar la sabiduría de las masas, es decir, reforzar el aprendizaje mediante el criterio de distintos metaestimadores que se encargarán de sacar sus propias conclusiones de respectivos datos seleccionados para luego, dependiendo del problema en cuestión, llegar a una respuesta final a través de la media o moda del conjunto de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustando modelo a través de PCA y KNN\n",
    "KNN_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "bagging_model = BaggingClassifier(estimator=KNN_classifier, # clasificador base\n",
    "                        n_estimators=100, # cantidad de estimadores\n",
    "                        max_samples=0.3) # número de muestras requeridas para cada modelo\n",
    "bagging_model.fit(df[[\"PCA_1\",\"PCA_2\"]].values, df[\"Outcome\"])\n",
    "\n",
    "object = [[df[\"Glucose\"].mean(), df[\"Insulin\"].mean(), df[\"BMI\"].mean(), df[\"SkinThickness\"].mean()]]\n",
    "\n",
    "pca_object = pca_model.transform(object)\n",
    "\n",
    "predict_encoded = bagging_model.predict(pca_object)\n",
    "\n",
    "map_diabetes = {\n",
    "    1:\"LP\",\n",
    "    0:\"HP\"\n",
    "}\n",
    "\n",
    "df[\"Outcome_no_encoded\"] = df[\"Outcome\"].apply(lambda x : map_diabetes.get(x))\n",
    "\n",
    "classes = list(zip(df[\"Outcome_no_encoded\"].unique(),df[\"Outcome\"].sort_values().unique()))\n",
    "\n",
    "# asociando la predicción a su clase\n",
    "\n",
    "predict_example = classes[predict_encoded[0]][0]\n",
    "\n",
    "probability = bagging_model.predict_proba(pca_object)\n",
    "\n",
    "probability = probability[0, predict_encoded]*100\n",
    "\n",
    "probability = str(probability[0])\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Nuevo objeto \\n\")\n",
    "for c in df.columns[:4]:\n",
    "    print(f\"{c}: {round(df[c].mean(),2)}\")\n",
    "    \n",
    "print(f\"\\npredicción: {predict_example} | probabilidad: {probability[:4]}%\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashboard interactivo que informa sobre medias y permite introducir datos para clasificarlos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__)\n",
    "\n",
    "high_progression = df.loc[df[\"Outcome\"] == 1,:]\n",
    "low_progression = df.loc[df[\"Outcome\"] == 0,:]\n",
    "\n",
    "colors_outcome = {\n",
    "    \"LP\":\"green\",\n",
    "    \"HP\":\"red\",\n",
    "}\n",
    "\n",
    "predict_text = html.B(children=[],id=\"predict\",style={})\n",
    "probability_text =  html.B(children=[],id=\"probability\")\n",
    "\n",
    "graph_pca = go.Figure()\n",
    "graph_pca.add_trace(go.Scatter(x=high_progression[\"PCA_1\"],y=high_progression[\"PCA_2\"],mode=\"markers\",marker_color=\"red\",name=\"HP\"))\n",
    "graph_pca.add_trace(go.Scatter(x=low_progression[\"PCA_1\"],y=low_progression[\"PCA_2\"],mode=\"markers\",marker_color=\"green\",name=\"LP\"))\n",
    "graph_pca.update_layout(title=\"PCA(principal components analysis)\")\n",
    "graph_pca.update_layout(legend=dict(font=dict(size=9)))\n",
    "\n",
    "app.layout =  html.Div(id=\"body\",className=\"e4_body\",children=[\n",
    "    html.H1(\"Diabetes's Progression\",id=\"title\",className=\"e4_title\"),\n",
    "    html.Div(id=\"dashboard\",className=\"e4_dashboard\",children=[\n",
    "        html.Div(className=\"e4_info_div\",children=[\n",
    "           html.H2(\"Diabetes's Means\",id=\"title_2\",className=\"e4_title_2\"),\n",
    "           html.Div(className=\"e4_info\",children=[\n",
    "              html.Img(id=\"img\",className=\"e4_img\", src=\"assets/diabetes.jpg\"),\n",
    "              html.Div(className=\"e4_ul_div\",children=[\n",
    "              html.Ul(className=\"e4_ul\", children=[\n",
    "                html.H3(\"High progression\",className=\"e4_title_2\"),\n",
    "                html.Li(f\"Glucose: {round(high_progression[\"Glucose\"].mean(),1)}\"),\n",
    "                html.Li(f\"Insulin: {round(high_progression[\"Insulin\"].mean(),1)}\"),\n",
    "                html.Li(f\"BMI: {round(high_progression[\"BMI\"].mean(),1)}\"),\n",
    "                html.Li(f\"Skin Thickness: {round(high_progression[\"SkinThickness\"].mean(),1)}\")\n",
    "              ]),\n",
    "              html.Ul(className=\"e4_ul\", children=[\n",
    "                html.H3(\"Low progression\",className=\"e4_title_2\"),\n",
    "                html.Li(f\"Glucose:{round(low_progression[\"Glucose\"].mean(),1)}\"),\n",
    "                html.Li(f\"Insulin: {round(low_progression[\"Insulin\"].mean(),1)}\"),\n",
    "                html.Li(f\"BMI: {round(low_progression[\"BMI\"].mean(),1)}\"),\n",
    "                html.Li(f\"Skin Thickness:{round(low_progression[\"SkinThickness\"].mean(),1)} \")\n",
    "              ])\n",
    "            ])\n",
    "           ])\n",
    "        ]),\n",
    "        html.Div(className=\"e4_graph_div\",children=[\n",
    "            dcc.Graph(id=\"graph-2\",className=\"e4_graph\",figure=graph_pca),\n",
    "            html.Form(id=\"input_div\",className=\"input_div\",children=[\n",
    "                dcc.Input(id=\"input_1\",className=\"input\",type=\"text\",placeholder=\"Glucose\",size=\"7\"),\n",
    "                dcc.Input(id=\"input_2\",className=\"input\",type=\"text\",placeholder=\"Insulin\",size=\"7\"),\n",
    "                dcc.Input(id=\"input_3\",className=\"input\",type=\"text\",placeholder=\"BMI\",size=\"7\"),\n",
    "                dcc.Input(id=\"input_4\",className=\"input\",type=\"text\",placeholder=\"Skin thickness\",size=\"7\"),\n",
    "                html.Button(\"enviar\",id=\"button\",type=\"button\",className=\"input\",n_clicks=0)\n",
    "            ]),\n",
    "            html.P([\"pred.: \",predict_text,\" | prob.: \",probability_text,\"%\"],className=\"e4_predict\")\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "        \n",
    "@app.callback(\n",
    "    [Output(component_id=\"graph-2\",component_property=\"figure\"),\n",
    "    Output(component_id=\"predict\",component_property=\"children\"),\n",
    "    Output(component_id=\"probability\",component_property=\"children\"),\n",
    "    Output(component_id=\"predict\",component_property=\"style\"),\n",
    "    Output(component_id=\"probability\",component_property=\"style\")],\n",
    "    [Input(component_id=\"button\",component_property=\"n_clicks\")],\n",
    "    [State(component_id=\"input_1\",component_property=\"value\"),\n",
    "    State(component_id=\"input_2\",component_property=\"value\"),\n",
    "    State(component_id=\"input_3\",component_property=\"value\"),\n",
    "    State(component_id=\"input_4\",component_property=\"value\")]\n",
    ")\n",
    "\n",
    "def update_graph(n_clicks, var_1, var_2, var_3, var_4):\n",
    "    if n_clicks is not None and n_clicks > 0:\n",
    "        object = [[var_1,var_2,var_3,var_4]]    \n",
    "        pca_object = pca_model.transform(object)\n",
    "        predict_encoded = bagging_model.predict(pca_object)\n",
    "        predict = classes[predict_encoded[0]][0]\n",
    "        predict_color = {\"color\":colors_outcome[predict]}\n",
    "        probability_color = {\"color\":colors_outcome[predict]}\n",
    "        probability = bagging_model.predict_proba(pca_object)\n",
    "        probability = probability[0,predict_encoded] * 100\n",
    "        probability = str(probability[0])\n",
    "        probability = probability[:4]\n",
    "        graph_pca.add_trace(go.Scatter(x=[pca_object[0,0]], y=[pca_object[0,1]], mode=\"markers\", marker_color=\"blueviolet\", name=f\"new object({predict})\"))\n",
    "    \n",
    "    return graph_pca, predict, probability, predict_color, probability_color\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
