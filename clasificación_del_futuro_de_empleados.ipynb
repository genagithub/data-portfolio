{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conceptos y técnicasc\n",
    "- Contexto y problema\n",
    "- Variables categóricas\n",
    "- Algoritmos CART\n",
    "- Métricas de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "df  = pd.read_csv(\"data/employee.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entendimiento del problema\n",
    "Entender el problema en Machine Learning es el primer paso a resolver de todo científico de datos, requiere de habilidades de escucha, comunicación, comprensión y pensamiento crítico. La meta es identificar y expresar con claridad el problema que se no asignó y la solución pedida, para ello necesitamos realizar las preguntas correctas y comunicar de forma clara nuestras deducciones. Este proyecto funciona como un ejemplo básico y trata sobre un conjunto de datos cuyo propósito es caracterizar mediante variables cualitativas(nominales y ordinales) y variables cuantitativas(discretas y continuas) a los empleados de un empresa y su futuro en esta, de esta forma es entendible que el objetivo es analizar y describir que ha sucedido para luego averiguar si afectaron ciertas características en la salida de un empleado, para despúes desarrollar un modelo que asocie un resultado a una clasificación en base a la información en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codificando variables categóricas nominales\n",
    "df_encoded = df.copy()\n",
    "df_encoded[[\"Education\",\"City\",\"Gender\",\"EverBenched\"]] = OrdinalEncoder().fit_transform(df[[\"Education\",\"City\",\"Gender\",\"EverBenched\"]])\n",
    "\n",
    "# a su vez generamos una versión categórica de la variable objetivo\n",
    "map = {\n",
    "    0:\"no\",\n",
    "    1:\"yes\"\n",
    "}\n",
    "df[\"LeaveOrNot_txt\"] = df[\"LeaveOrNot\"].apply(lambda x : map.get(x))\n",
    "\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Categóricas y Datasets Desbalanceados\n",
    "La función de las variables categóricas es brindar información clasificando las observaciones, puenden demostrar una influencia en los datos permitiendonos determinar comportamientos o sacar conclusiones premeditadas si los datos influyen en estas. Los Trip_Priceos de variables categóricas que hay son nominales: aquellas que actúan como etiquetas de los objetos(dentro de estas pueden encontrarse las que se dividen en 2 clases y su codificación las convierte en binarias, es decir, valores posibles de 0 o 1) y ordinales: aquellas que representan un órden jerárquico en particular que rige en las observaciones.\n",
    "\n",
    "En algunos casos los datasets tienden a contener más cantidades de datos categóricos que otros, esto puede llegar a traer problemas la hora de entrenar un modelo o evaluar el desempeño de este debido a que la variable minoritaria tiende a ser ignorada y genera un sesgo en cuanto a la importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_count = df[\"LeaveOrNot\"].value_counts().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].bar(var_count[\"LeaveOrNot\"], var_count[\"count\"], color=[\"b\",\"orange\"])\n",
    "ax[0].grid(\"on\")\n",
    "ax[0].set_title('Conteo de clases')\n",
    "ax[1].pie(var_count[\"count\"], labels=var_count[\"LeaveOrNot\"], autopct='%1.1f%%')\n",
    "ax[1].set_title('Porciones de clase')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CART(classification and regression trees)\n",
    "Algoritmos basados en calcular umbrales que determinen el resultado de una variable, de manera iterativa se generan particiones sobre la región de información hasta llegar a una formación de grupo lo más homogénea posible. Haciendo analogía a la estructura de un árbol, a partir de la raíz principal se extienden nodos adicionales que representan una condición y hojas que indican la pureza en su región de clases, de esta manera su trayectoria consiste en integorrantes de si o no junto con respuestas asociadas y la fiabilidad de estas. El modelado a partir de esta técnica de aprendizaje requiere controlar la complejidad del árbol de decisión, siendo la pre-poda la acción de limitar el crecimiento durante el proceso de entrenamiento y la post-poda lo mismo luego de este último, esto se realiza mediante la programación de valores númericos definidos y asignados por el usuario, es decir, un ajuste de hiperparámetros y aglunos ejemplos son definir la profundidad máxima o el mínimo número de muestras requeridas para cada partición o hoja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seccionamos los datos en grupos de entrenamiento y prueba\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                   df_encoded[df_encoded.columns[:-1]],\n",
    "                                                   df_encoded[\"LeaveOrNot\"],\n",
    "                                                   test_size=0.1)\n",
    "\n",
    "# declaración del algoritmo\n",
    "\n",
    "tree_decision_clf = tree.DecisionTreeClassifier(criterion=\"entropy\", # medida de aleatoriedad, determinará los nodos del modelo en base a la probabilidad de clasificar erroneamente una variable, pero sin darle mayor importancias a ciertas características\n",
    "                                           max_depth=6, # distancia entre el nodo(condición) principal y la última hoja(respuesta asociada), valores recomendados: 3-10\n",
    "                                           min_samples_split=6, # mínimo número de muestras requeridas para dividir un nodo, valores recomendados: 2-10\n",
    "                                           min_samples_leaf=5, #  mínimo número de muestras requeridas en cada hoja, valores recomendados: 1-10\n",
    "                                           ccp_alpha=0.003) # valor de post-poda(luego de que el modelo se ajute) que evita el sobreajuste \n",
    "\n",
    "model = tree_decision_clf.fit(x_train, y_train)\n",
    "\n",
    "# predicción de datos de prueba\n",
    "\n",
    "class_predicts = model.predict(x_test)\n",
    "\n",
    "class_real = y_test.values\n",
    "\n",
    "# Matriz de confusión: recolecta los aciertos y desaciertos tanto de la clase postiva como negativa del modelo\n",
    "\n",
    "matrix_confusion = confusion_matrix(class_real,class_predicts)\n",
    "TP = matrix_confusion[0,0]\n",
    "FP = matrix_confusion[0,1]\n",
    "FN = matrix_confusion[1,0]\n",
    "TN = matrix_confusion[1,1]\n",
    "\n",
    "# Accuracy: indica la acertividad general de nuestro modelo con respecto a las nuevas observaciones\n",
    "\n",
    "accuracy = accuracy_score(class_real, class_predicts)\n",
    "color_accuracy = \"green\"\n",
    "if accuracy < 0.6:\n",
    "    color_accuracy = \"red\"\n",
    "accuracy_str = str(accuracy)\n",
    "\n",
    "# Recall: es utilizada para poder saber la efectividad de nuestro modelo a la hora de predecir valores de la clase positiva\n",
    "\n",
    "recall = recall_score(class_real, class_predicts)\n",
    "color_recall = \"green\"\n",
    "if recall < 0.6:\n",
    "    color_recall = \"red\"\n",
    "recall_str = str(recall)\n",
    "\n",
    "# Precision: es utilizada para poder saber que porcentage de valores que fueron clasificados como positivos son realmente positivos\n",
    "\n",
    "precision = precision_score(class_real, class_predicts)\n",
    "color_precision = \"green\"\n",
    "if precision < 0.6:\n",
    "    color_precision = \"red\"\n",
    "precision_str = str(precision)\n",
    "\n",
    "# F1 Score: es utilizada como un resumen de las dos últimas métricas\n",
    "\n",
    "F1_score = f1_score(class_real, class_predicts)\n",
    "color_f1 = \"green\"\n",
    "if F1_score < 0.6:\n",
    "    color_f1 = \"red\"\n",
    "F1_score_str = str(F1_score)\n",
    "\n",
    "plt.figure(figsize=(32,22))\n",
    "tree.plot_tree(model, feature_names=df_encoded.columns[:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashboard que describe las características de los empleados según su futuro y el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación de dashboard basado en la estructura HTML/CSS\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(id=\"body\",className=\"e1_body\",children=[\n",
    "html.H1(\"Futuro de Empleados\",id=\"title\",className=\"e1_title\"),\n",
    "html.Div(className=\"e1_dashboards\",children=[\n",
    "    html.Div(id=\"graph_div_1\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_1\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_1\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Educación\",\"value\":\"Education\"},\n",
    "                            {\"label\":\"Año de incorporación\",\"value\":\"JoiningYear\"},\n",
    "                            {\"label\":\"Ciudad\",\"value\":\"City\"},\n",
    "                            {\"label\":\"Género\",\"value\":\"Gender\"},\n",
    "                            {\"label\":\"Siempre en banca\",\"value\":\"EverBenched\"}\n",
    "                        ],\n",
    "                        value=\"Education\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"piechart\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "    html.Div(id=\"graph_div_2\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_2\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_2\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Edad\",\"value\":\"Age\"},\n",
    "                            {\"label\":\"Nivel de pago\",\"value\":\"PaymentTier\"},\n",
    "                            {\"label\":\"Experiencia en el dominio\",\"value\":\"ExperienceInCurrentDomain\"}\n",
    "                        ],\n",
    "                        value=\"Age\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"bar\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "]),\n",
    "    \n",
    "    html.Div(className=\"e1_div\", children=[\n",
    "        html.Div(id=\"performance\", className=\"e1_performance\",children=[\n",
    "            html.P([html.B(\"Clases reales\", style={\"color\":\"blue\"}),\"   |   \",html.B(\"Predicciones\",style={\"color\":\"red\"})], style={\"text-align\":\"center\",\"font-family\":\"sans-serif\"}),\n",
    "            html.P(\"--------------------------------------------------------------------------------------------------------------------------------------\",style={\"margin\":\"0\"}),\n",
    "            html.P(f\"{class_real}\", className=\"e1_real_class\"),\n",
    "            html.P(f\"{class_predicts}\", className=\"e1_predicts\")\n",
    "        ]),\n",
    "        html.Div(id=\"metrics\", className=\"e1_metrics\", children=[\n",
    "                html.P(\"Matriz de confusión\", style={\"font-size\":\"0.9em\",\"text-align\":\"center\",\"font-family\":\"sans-serif\",\"font-weigth\":\"bold\"}),\n",
    "                html.Div(id=\"matrix\", className=\"e1_matrix\", children=[\n",
    "                html.Div([html.B(TP,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TP\",className=\"e1_successes\"), \n",
    "                html.Div([html.B(FP,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FP\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(FN,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FN\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(TN,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TN\",className=\"e1_successes\")\n",
    "                ]),\n",
    "                html.Div(id=\"scores\",children=[\n",
    "                html.Ul(id=\"list\",children=[\n",
    "                html.Li([f\"Accuracy: \",html.B(accuracy_str[:4],style={\"color\":f\"{color_accuracy}\"})],id=\"accuracy\",className=\"e1_score\"),\n",
    "                html.Li([f\"Recall: \",html.B(recall_str[:4],style={\"color\":f\"{color_recall}\"})],id=\"recall\",className=\"e1_score\"),\n",
    "                html.Li([f\"Precision: \",html.B(precision_str[:4],style={\"color\":f\"{color_precision}\"})],id=\"precision\",className=\"e1_score\"),\n",
    "                html.Li([f\"F1 Score: \",html.B(F1_score_str[:4],style={\"color\":f\"{color_f1}\"})],id=\"f1_score\",className=\"e1_score\")\n",
    "                ])\n",
    "                \n",
    "            ])\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "# generan interacción entre los datos de entrada y los elementos que serán modificados \n",
    "\n",
    "@app.callback(\n",
    "    [Output(component_id=\"piechart\",component_property=\"figure\"),\n",
    "    Output(component_id=\"bar\",component_property=\"figure\")],\n",
    "    [Input(component_id=\"dropdown_1\",component_property=\"value\"),\n",
    "    Input(component_id=\"dropdown_2\",component_property=\"value\")]\n",
    ")\n",
    "\n",
    "# función que se ejecuta cada vez que se interactúa con los elementos \n",
    "\n",
    "def update_graph(slct_var_cat,slct_var_num):\n",
    "    \n",
    "    df[\"JoiningYear\"] = df[\"JoiningYear\"].astype(str)\n",
    "    df_percentage = df.groupby(slct_var_cat)[\"LeaveOrNot\"].mean().reset_index()\n",
    "    df_percentage[\"LeaveOrNot\"] = round(df_percentage[\"LeaveOrNot\"] * 100)\n",
    "    df_percentage[\"LeaveOrNot\"] = df_percentage[\"LeaveOrNot\"].astype(str)\n",
    "    df_percentage[\"var_percentage\"] = df_percentage[slct_var_cat].astype(str)+\"(\"+df_percentage[\"LeaveOrNot\"]+\"%)\"\n",
    "    \n",
    "    piechart = px.pie(df_percentage, values=\"LeaveOrNot\", names=\"var_percentage\", title=\"Probabilidad de Salida\")\n",
    "    \n",
    "    df_mean = df.groupby(\"LeaveOrNot_txt\")[slct_var_num].mean().reset_index()\n",
    "    \n",
    "    barplot = px.bar(df_mean, x=\"LeaveOrNot_txt\", y=slct_var_num, title=\"Medias Estadísticas\", labels={\"x\":\"empleados\",\"y\":slct_var_num})\n",
    "    barplot.update_layout(xaxis_title=\"Leave or Not\")\n",
    "    \n",
    "    return piechart,barplot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error de varianza\n",
    "\n",
    "Es la variabilidad que existe en la función objetivo con respecto a los diferentes datos de entrenamiento que se utilicen para la creación del modelo, sucede principalmente en algoritmos que se ajustan fácilmente a los datos y requieren menos suposiciones a diferencia de los algoritmos con alto bías, algunos ejemplos de algoritmos con alta variranza son: KNN, CART o SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "bucle = list(range(14))\n",
    "\n",
    "for i in bucle:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                   df_encoded[df_encoded.columns[:-1]],\n",
    "                                                   df_encoded[\"LeaveOrNot\"],\n",
    "                                                   test_size=0.25)\n",
    "    class_real = y_test.values\n",
    "    class_predicts = model.predict(x_test)\n",
    "    accuracy = accuracy_score(class_real, class_predicts)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(bucle, accuracies, marker=\"*\", c=\"r\")\n",
    "plt.grid(\"on\")\n",
    "plt.title(\"Error de Varianza\")\n",
    "plt.ylabel(\"Acuracies\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
